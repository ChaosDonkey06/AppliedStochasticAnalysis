{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as dist\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_exponential(num_samples=100, num_repetitions=1, λ=1):\n",
    "    \"\"\" Sample from exponential distribution with parameter λ.\n",
    "\n",
    "    Args:\n",
    "        num_samples (int, optional): Number of independent samples. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "        np.array: column vector of samples of size [num_samples, 1]\n",
    "    \"\"\"\n",
    "    return dist.exponential(λ, [num_samples, num_repetitions])\n",
    "\n",
    "def compute_sample_average(samples):\n",
    "    \"\"\" Compute the sample average of a column vector.\n",
    "\n",
    "    Args:\n",
    "        samples (np.array): column vector of samples, size [num_samples, 1]\n",
    "\n",
    "    Returns:\n",
    "        np.float64: sample average\n",
    "    \"\"\"\n",
    "    return np.mean(samples, 0)\n",
    "\n",
    "def compute_sample_variance(samples):\n",
    "    \"\"\" Compute the sample variance of a column vector.\n",
    "\n",
    "    Args:\n",
    "        samples (np.array): column vector of samples, size [num_samples, 1]\n",
    "\n",
    "    Returns:\n",
    "        np.float64: sample variance\n",
    "    \"\"\"\n",
    "    return np.var(samples, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_samples     = 1000\n",
    "num_repetitions = 10000\n",
    "\n",
    "samples = sample_exponential(num_samples, num_repetitions)\n",
    "\n",
    "f_ave = compute_sample_average(samples)\n",
    "f_var = compute_sample_variance(f_ave)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chebyshev_prob(f_ave, π_f=1, ε=1e-2):\n",
    "    n      = f_ave.shape[0]\n",
    "    P_cheb = np.sum(np.abs(f_ave - π_f)>ε)/n\n",
    "    return P_cheb\n",
    "\n",
    "def compute_numerical_bound(f_ave_var, ε=1e-2):\n",
    "    P_bound_meas = f_ave_var/(ε**2)\n",
    "    return P_bound_meas\n",
    "\n",
    "def compute_theoretical_bound(σ2=1, ε=1e-2, n=1000):\n",
    "    P_bound_theo = σ2/(n * ε**2)\n",
    "    return P_bound_theo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by chebyshev\n",
    "ε   = 1e-4\n",
    "π_f = 1\n",
    "σ2  = 1\n",
    "\n",
    "P_chebyshev  = []\n",
    "P_num_bound  = []\n",
    "P_theo_bound = []\n",
    "\n",
    "epsilons = np.linspace(1e-4, 1e-1, 300)\n",
    "\n",
    "for εi in epsilons:\n",
    "    P_chebyshev.append(compute_chebyshev_prob(f_ave, π_f, εi))\n",
    "    P_num_bound.append(compute_numerical_bound(f_var, εi))\n",
    "    P_theo_bound.append(compute_theoretical_bound(σ2, εi, num_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7.2, 5))\n",
    "\n",
    "ax.plot(epsilons, P_chebyshev,  lw=2, ls=\"-\",  color=\"k\",      label  = r'$P\\left(\\left|\\bar{f}_N-\\pi(f)\\right|>\\epsilon\\right)$')\n",
    "ax.plot(epsilons, P_num_bound,  lw=2, ls=\"-\",  color=\"salmon\", label  = r'Chebyshev, numerical bound. $\\mathrm{Var}\\left(\\bar{f}_N\\right)/\\epsilon^2$')\n",
    "ax.plot(epsilons, P_theo_bound, lw=2, ls=\"-.\", color=\"teal\",   label = r'Chebyshev, theoretical bound. $\\sigma^2/(\\epsilon^2\\cdot N)$')\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(r'$\\mathbf{ε}$')\n",
    "ax.legend()\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "fig.savefig(os.path.join(\".\", \"prob01_WLLN.png\"),\n",
    "                                            dpi=300, transparent=True, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_normal(num_samples=100, μ=0, σ=1):\n",
    "    \"\"\" Sample from normal distribution with parameters μ and σ.\n",
    "\n",
    "    Args:\n",
    "        num_samples (int, optional): Number of independent samples. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "        np.array: column vector of samples of size [num_samples, 1]\n",
    "    \"\"\"\n",
    "    return dist.normal(μ, σ, [num_samples])\n",
    "\n",
    "def normal_distribution(x, μ=0, σ=1):\n",
    "    return (1/(σ*np.sqrt(2*np.pi)))*np.exp(-0.5*((x-μ)/σ)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "λ = 1\n",
    "x = np.linspace(0.8, 1.2, 1000)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(12, 5))\n",
    "\n",
    "for i, num_samples in enumerate([10, 100, 1000, 10000]):\n",
    "\n",
    "    num_samples = int(num_samples)\n",
    "\n",
    "    num_repetitions = int(1000)\n",
    "    exp_samples     = sample_exponential(num_samples, num_repetitions)\n",
    "    f_ave           = compute_sample_average(exp_samples)\n",
    "\n",
    "    f_clt = sample_normal(num_samples=int(1e6), μ=λ, σ=(1/λ**2)/np.sqrt(num_samples))\n",
    "    Xn    = normal_distribution(x, μ=λ, σ=(1/λ**2)/np.sqrt(num_samples))\n",
    "\n",
    "\n",
    "    ax[i].plot(x, Xn, lw=2, ls=\"--\", color=\"k\", label=r'$\\mathcal{N}\\left(\\mu=\\lambda, \\sigma^2=\\frac{1}{\\lambda^2\\sqrt{N}}\\right)$')\n",
    "    ax[i].hist(f_ave, bins=100, density=True, color=\"salmon\", alpha=0.5, label=r'$\\bar{f}_N$ distribution')\n",
    "\n",
    "    ax[i].set_title(r'$N={}$'.format(num_samples))\n",
    "\n",
    "for axi in ax:\n",
    "    axi.spines['right'].set_visible(False)\n",
    "    axi.spines['top'].set_visible(False)\n",
    "    axi.set_xlim((0.78, 1.22))\n",
    "\n",
    "ax[0].legend(loc='upper left', bbox_to_anchor=(0.0, 1.25), ncol=2)\n",
    "\n",
    "fig.supxlabel(r'$\\bar{f}_N$', y=-.01)\n",
    "\n",
    "fig.savefig(os.path.join(\".\", \"prob01_CLT.png\"),\n",
    "                                            dpi=300, transparent=True, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crps(pred_samples, truth):\n",
    "    num_samples = pred_samples.shape[0]\n",
    "    pred   = np.sort(pred_samples)\n",
    "    diff   = pred[1:] - pred[:-1]\n",
    "    weight = np.arange(1, num_samples) * np.arange( num_samples - 1, 0, -1)\n",
    "\n",
    "    return np.abs(pred - truth).mean(0) - (diff * weight).sum(0) / num_samples**2\n",
    "\n",
    "def Kullback_Leibler(p, q):\n",
    "    kl = p*np.log(p/q)\n",
    "    return kl[np.isfinite(kl)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_arr = np.logspace(1.0, 5.0, num=30)\n",
    "\n",
    "Var_f        = np.full(num_samples_arr.shape, np.nan)\n",
    "error_f      = np.full(num_samples_arr.shape, np.nan)\n",
    "error_normal = np.full(num_samples_arr.shape, np.nan)\n",
    "\n",
    "error_clt = np.full(num_samples_arr.shape, np.nan)\n",
    "\n",
    "bins      = np.linspace(0.75, 1.25, 1000)\n",
    "\n",
    "i = 0\n",
    "for num_samples in tqdm.tqdm(num_samples_arr):\n",
    "\n",
    "    num_samples = int(num_samples)\n",
    "\n",
    "    num_repetitions = int(1000)\n",
    "    exp_samples     = sample_exponential(num_samples, num_repetitions)\n",
    "\n",
    "\n",
    "    f_ave       = compute_sample_average(exp_samples)\n",
    "    f_clt       = sample_normal(num_samples=int(num_samples), μ=λ, σ=(1/λ**2)/np.sqrt(num_samples))\n",
    "\n",
    "    Var_f[i]     = np.var(f_ave)\n",
    "\n",
    "\n",
    "    error_f[i]      = crps(f_ave, np.array([1]))\n",
    "    error_normal[i] = crps(f_clt, np.array([1]))\n",
    "\n",
    "    p_f_ave, _ = np.histogram(f_ave, bins=bins)\n",
    "    p_f_sim, _ = np.histogram(f_clt, bins=bins)\n",
    "\n",
    "    error_clt[i] = Kullback_Leibler(p_f_ave, p_f_sim)\n",
    "\n",
    "    Xn       = normal_distribution(x, μ=λ, σ=(1/λ**2)/np.sqrt(num_samples))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10.5, 5), sharex=True)\n",
    "\n",
    "ax[0].plot(num_samples_arr, np.sqrt(Var_f), lw=3, ls=\"-\",  color=\"darkred\", label=r'$\\mathrm{Var}\\left(\\bar{f}_N\\right)$')\n",
    "ax[0].plot(num_samples_arr, (1/λ**2)/np.sqrt(num_samples_arr), lw=2, ls=\"--\",  color=\"darkgrey\", label=r'$\\sigma^2=\\frac{1}{\\lambda^2\\sqrt{N}}$')\n",
    "\n",
    "ax[1].plot(num_samples_arr, error_f, lw=3, ls=\"-\",  color=\"salmon\", label=r'Monte Carlo approx')\n",
    "ax[1].plot(num_samples_arr, error_normal, lw=2, ls=\"--\",  color=\"k\", label=r'CLT approx')\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_ylabel(r'Monte Carlo uncertainty')\n",
    "\n",
    "ax[1].set_ylabel(r'Monte Carlo error')\n",
    "\n",
    "\n",
    "ax[0].legend(loc=\"upper left\", ncol=2, frameon=False, bbox_to_anchor=(0.0, 1.1))\n",
    "ax[1].legend(loc=\"upper left\", ncol=1, frameon=False, bbox_to_anchor=(0.0, 1.15))\n",
    "\n",
    "#ax[2].plot(num_samples_arr, error_clt, lw=2, ls=\"-\",  color=\"teal\", label=r'$KL\\left(MC\\left(\\bar{f}_N\\right), \\mathcal{N}\\left(\\mu=\\lambda, \\sigma^2=\\frac{1}{\\lambda^2\\sqrt{N}}\\right)\\right)$')\n",
    "#ax[2].legend(loc=\"upper left\",  bbox_to_anchor=(0.0, 1.1), frameon=False)\n",
    "#ax[2].set_ylabel(r'CLT error')\n",
    "\n",
    "for axi in ax:\n",
    "    axi.spines['right'].set_visible(False)\n",
    "    axi.spines['top'].set_visible(False)\n",
    "\n",
    "fig.supxlabel(r'Sample size, $N$', y=-.01)\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(\".\", \"prob01_MC-CLT_error.png\"),\n",
    "                                            dpi=300, transparent=True, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concentration inequality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ia(f_bar=1, pi_f=1, a=1e-3, λ=1):\n",
    "\n",
    "    ldp_o  = λ*a - np.log(np.mean(np.exp(λ*(f_bar - pi_f))))\n",
    "\n",
    "    return np.max(ldp_o)\n",
    "\n",
    "def compute_chernoff_prob(f_ave, π_f=1, a=1e-2):\n",
    "    n      = f_ave.shape[0]\n",
    "\n",
    "    P_cher = np.sum(f_ave - π_f>=a)/n\n",
    "    return P_cher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples     = 1000\n",
    "num_repetitions = 1000\n",
    "\n",
    "π_f          = 1\n",
    "exp_samples  = sample_exponential(num_samples, num_repetitions)\n",
    "\n",
    "epsilon = np.linspace(1e-3, 0.05, 100)\n",
    "\n",
    "P_chernoff   = np.full(epsilon.shape, np.nan)\n",
    "P_cher_bound = np.full(epsilon.shape, np.nan)\n",
    "\n",
    "λ = 0.01\n",
    "\n",
    "for i, εi in enumerate(epsilon):\n",
    "\n",
    "    P_chernoff[i]   = compute_chernoff_prob(f_ave, π_f, a=εi)\n",
    "    P_cher_bound[i] = np.exp(-num_samples*Ia(f_ave, π_f, a=εi, λ=λ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12.2, 5), sharex=True, sharey=True)\n",
    "\n",
    "for il, λ in enumerate([0.01, 0.1, 0.5]):\n",
    "    P_chernoff   = np.full(epsilon.shape, np.nan)\n",
    "    P_cher_bound = np.full(epsilon.shape, np.nan)\n",
    "\n",
    "    for i, εi in enumerate(epsilon):\n",
    "\n",
    "        P_chernoff[i]   = compute_chernoff_prob(f_ave, π_f, a=εi)\n",
    "        P_cher_bound[i] = np.exp(-num_samples*Ia(f_ave, π_f, a=εi, λ=λ))\n",
    "\n",
    "    ax[il].plot(epsilon, P_chernoff,  lw=2, ls=\"-\",  color=\"k\",      label  = r'$P\\left( \\bar{f}_N-\\pi(f)\\geq a\\right)$')\n",
    "    ax[il].plot(epsilon, P_cher_bound,  lw=2, ls=\"-\",  color=\"salmon\", label  = r'Chernoff bound, $\\exp\\left(-N\\cdot I(a)\\right)$')\n",
    "\n",
    "    ax[il].set_title(\"λ={}\".format(λ))\n",
    "\n",
    "for axi in ax.flatten():\n",
    "    axi.spines['right'].set_visible(False)\n",
    "    axi.spines['top'].set_visible(False)\n",
    "\n",
    "    axi.set_yscale('logit')\n",
    "    axi.set_xscale('logit')\n",
    "\n",
    "\n",
    "fig.supylabel(r'probability', weight=\"bold\")\n",
    "fig.supxlabel(r'$\\mathbf{a}$', y=-0.1)\n",
    "\n",
    "ax[0].legend(loc=\"lower left\",  frameon=True, ncol=1)\n",
    "\n",
    "ax[0].tick_params(axis='x', which=\"both\", labelrotation=90)\n",
    "ax[1].tick_params(axis='x', which=\"both\", labelrotation=90)\n",
    "ax[2].tick_params(axis='x', which=\"both\", labelrotation=90)\n",
    "\n",
    "fig.savefig(os.path.join(\".\", \"prob01_Chernoff.png\"), dpi=300, transparent=True, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
